{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The objective of this project is to analyze the collected hard drive  dataset for XYZ Corporation. We will build a model to predict when a hard drive will fail based on features of the SMART 255 variable system data.\n",
    "\n",
    "Utilization of the predictive model will aid in solving XYZ Corporation's IT hardware costs by lowering costs associated with unexpected hard drive failures - such as delayed work due to downtime and stress applied to internal processes to replace the drives quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "First step is to import our source data into our environment to begin our analysis. To do this we will import the collected dataset CSV Files from our local machine. \n",
    "\n",
    "To import our dataset we will utilize the **Pandas** python library. **Pandas** is a handy open-source data analysis library. \n",
    "\n",
    "Since our source datasets are located on our local machine we will all leverage the **glob** python library to help with local file system operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob         # Load glob libraries\n",
    "import pandas as pd # Load the Pandas libraries with alias 'pd'\n",
    "\n",
    "# Path to dataset file directory within workspace\n",
    "path = \"./data_Q1_2018/\"\n",
    "\n",
    "# glob.glob(path + '*.csv') - returns List[str]\n",
    "# pd.read_csv(f) - returns pd.DataFrame()\n",
    "# for f in glob.glob() - returns a List[DataFrames]\n",
    "# pd.concat() - returns one pd.DataFrame()\n",
    "df = pd.concat([pd.read_csv(f, encoding='latin1') for f in glob.glob(path + '*.csv')])\n",
    "\n",
    "# Check to see all data files were loaded - we know that there are 90 csv files once the \n",
    "# Zip file is extracted, so the Out[] should equal 90 if all csv files were properly loaded.\n",
    "df.date.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration & Cleansing\n",
    "Now that the CSV data files have been loaded into **Pandas** and combined into one DataFrame, we can begin our data exploration.\n",
    "\n",
    "We'll start by checking out the first 5 rows (default) of the DataFrame to get a quick look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>model</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>failure</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_1_raw</th>\n",
       "      <th>smart_2_normalized</th>\n",
       "      <th>smart_2_raw</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_250_normalized</th>\n",
       "      <th>smart_250_raw</th>\n",
       "      <th>smart_251_normalized</th>\n",
       "      <th>smart_251_raw</th>\n",
       "      <th>smart_252_normalized</th>\n",
       "      <th>smart_252_raw</th>\n",
       "      <th>smart_254_normalized</th>\n",
       "      <th>smart_254_raw</th>\n",
       "      <th>smart_255_normalized</th>\n",
       "      <th>smart_255_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>Z305B2QN</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>179547432.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>PL1331LAHG1S4H</td>\n",
       "      <td>HGST HMS5C4040ALE640</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>ZA16NQJR</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>67614504.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>ZA18CEBT</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1580176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>ZA18CEBS</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>161864784.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   serial_number                 model  capacity_bytes  failure  \\\n",
       "0  2018-02-04        Z305B2QN           ST4000DM000   4000787030016        0   \n",
       "1  2018-02-04  PL1331LAHG1S4H  HGST HMS5C4040ALE640   4000787030016        0   \n",
       "2  2018-02-04        ZA16NQJR          ST8000NM0055   8001563222016        0   \n",
       "3  2018-02-04        ZA18CEBT          ST8000NM0055   8001563222016        0   \n",
       "4  2018-02-04        ZA18CEBS          ST8000NM0055   8001563222016        0   \n",
       "\n",
       "   smart_1_normalized  smart_1_raw  smart_2_normalized  smart_2_raw  \\\n",
       "0               118.0  179547432.0                 NaN          NaN   \n",
       "1               100.0          0.0               134.0        102.0   \n",
       "2                78.0   67614504.0                 NaN          NaN   \n",
       "3               100.0    1580176.0                 NaN          NaN   \n",
       "4                82.0  161864784.0                 NaN          NaN   \n",
       "\n",
       "   smart_3_normalized      ...        smart_250_normalized  smart_250_raw  \\\n",
       "0                91.0      ...                         NaN            NaN   \n",
       "1               100.0      ...                         NaN            NaN   \n",
       "2                94.0      ...                         NaN            NaN   \n",
       "3                96.0      ...                         NaN            NaN   \n",
       "4                97.0      ...                         NaN            NaN   \n",
       "\n",
       "   smart_251_normalized  smart_251_raw  smart_252_normalized  smart_252_raw  \\\n",
       "0                   NaN            NaN                   NaN            NaN   \n",
       "1                   NaN            NaN                   NaN            NaN   \n",
       "2                   NaN            NaN                   NaN            NaN   \n",
       "3                   NaN            NaN                   NaN            NaN   \n",
       "4                   NaN            NaN                   NaN            NaN   \n",
       "\n",
       "   smart_254_normalized  smart_254_raw  smart_255_normalized  smart_255_raw  \n",
       "0                   NaN            NaN                   NaN            NaN  \n",
       "1                   NaN            NaN                   NaN            NaN  \n",
       "2                   NaN            NaN                   NaN            NaN  \n",
       "3                   NaN            NaN                   NaN            NaN  \n",
       "4                   NaN            NaN                   NaN            NaN  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first 5 lines of the loaded data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8949492, 105)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the row and column count of the DataFrame to illustrate shape of the dataset.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic Approach\n",
    "Now that we have a better idea of the data within the DataFrame we need to make three distinctions to choice the right path forward with our analysis.\n",
    "\n",
    "1. Is this going to be supervised or unsupervised learning?   \n",
    "We have a defined dependent or y variable, 'failure', allowing **Supervised Learning** to be performed. The computer to learn from our clearly labeled dataset.   \n",
    "\n",
    "\n",
    "2. Is this a classification or regression problem?   \n",
    "One way to identify the type of problem is to look at the y variable to see if it is discrete or continuous, and if its categorical or quantitative. Since 'failure' is discrete and categorical in nature, this is a **Classification** problem, specifically this is a **Binary Classification** problem because each hard drive for a given day has either failed or not.\n",
    "\n",
    "\n",
    "3. Is this a prediction or inference problem?   \n",
    "The business use case is to create a model to be leverage to estimate when a hard drive will fail, therefore this is **Prediction** problem. We will want the model to estimate a y ('Failure') value, given a variety of features.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "Since there are a large number (105) of features in this dataset this would take a really long time to train and test, as well as leading to potential overfitting. Next, we need to determine which features we think are likely to be important our target variable to help reduce the computational workload and improve performance. \n",
    "\n",
    "One way is review a more concise summary of the DataFrame. The **info()** method in the **Pandas** library allows us to do just that by printing information about a DataFrame including the index dtype and column dtypes, non-null values and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8949492 entries, 0 to 100349\n",
      "Data columns (total 105 columns):\n",
      "date                    8949492 non-null object\n",
      "serial_number           8949492 non-null object\n",
      "model                   8949492 non-null object\n",
      "capacity_bytes          8949492 non-null int64\n",
      "failure                 8949492 non-null int64\n",
      "smart_1_normalized      8948907 non-null float64\n",
      "smart_1_raw             8948907 non-null float64\n",
      "smart_2_normalized      2235026 non-null float64\n",
      "smart_2_raw             2235026 non-null float64\n",
      "smart_3_normalized      8948907 non-null float64\n",
      "smart_3_raw             8948907 non-null float64\n",
      "smart_4_normalized      8948907 non-null float64\n",
      "smart_4_raw             8948907 non-null float64\n",
      "smart_5_normalized      8949141 non-null float64\n",
      "smart_5_raw             8949141 non-null float64\n",
      "smart_7_normalized      8948907 non-null float64\n",
      "smart_7_raw             8948907 non-null float64\n",
      "smart_8_normalized      2235026 non-null float64\n",
      "smart_8_raw             2235026 non-null float64\n",
      "smart_9_normalized      8949141 non-null float64\n",
      "smart_9_raw             8949141 non-null float64\n",
      "smart_10_normalized     8948907 non-null float64\n",
      "smart_10_raw            8948907 non-null float64\n",
      "smart_11_normalized     160729 non-null float64\n",
      "smart_11_raw            160729 non-null float64\n",
      "smart_12_normalized     8949141 non-null float64\n",
      "smart_12_raw            8949141 non-null float64\n",
      "smart_13_normalized     0 non-null float64\n",
      "smart_13_raw            0 non-null float64\n",
      "smart_15_normalized     0 non-null float64\n",
      "smart_15_raw            0 non-null float64\n",
      "smart_22_normalized     94024 non-null float64\n",
      "smart_22_raw            94024 non-null float64\n",
      "smart_177_normalized    234 non-null float64\n",
      "smart_177_raw           234 non-null float64\n",
      "smart_179_normalized    234 non-null float64\n",
      "smart_179_raw           234 non-null float64\n",
      "smart_181_normalized    234 non-null float64\n",
      "smart_181_raw           234 non-null float64\n",
      "smart_182_normalized    234 non-null float64\n",
      "smart_182_raw           234 non-null float64\n",
      "smart_183_normalized    3019247 non-null float64\n",
      "smart_183_raw           3019247 non-null float64\n",
      "smart_184_normalized    5319401 non-null float64\n",
      "smart_184_raw           5319401 non-null float64\n",
      "smart_187_normalized    6615876 non-null float64\n",
      "smart_187_raw           6615876 non-null float64\n",
      "smart_188_normalized    6615642 non-null float64\n",
      "smart_188_raw           6615642 non-null float64\n",
      "smart_189_normalized    5319401 non-null float64\n",
      "smart_189_raw           5319401 non-null float64\n",
      "smart_190_normalized    6615876 non-null float64\n",
      "smart_190_raw           6615876 non-null float64\n",
      "smart_191_normalized    5474396 non-null float64\n",
      "smart_191_raw           5474396 non-null float64\n",
      "smart_192_normalized    8944409 non-null float64\n",
      "smart_192_raw           8944409 non-null float64\n",
      "smart_193_normalized    8881919 non-null float64\n",
      "smart_193_raw           8881919 non-null float64\n",
      "smart_194_normalized    8948907 non-null float64\n",
      "smart_194_raw           8948907 non-null float64\n",
      "smart_195_normalized    3850190 non-null float64\n",
      "smart_195_raw           3850190 non-null float64\n",
      "smart_196_normalized    2333265 non-null float64\n",
      "smart_196_raw           2333265 non-null float64\n",
      "smart_197_normalized    8948907 non-null float64\n",
      "smart_197_raw           8948907 non-null float64\n",
      "smart_198_normalized    8948907 non-null float64\n",
      "smart_198_raw           8948907 non-null float64\n",
      "smart_199_normalized    8949141 non-null float64\n",
      "smart_199_raw           8949141 non-null float64\n",
      "smart_200_normalized    1566708 non-null float64\n",
      "smart_200_raw           1566708 non-null float64\n",
      "smart_201_normalized    0 non-null float64\n",
      "smart_201_raw           0 non-null float64\n",
      "smart_220_normalized    81408 non-null float64\n",
      "smart_220_raw           81408 non-null float64\n",
      "smart_222_normalized    81408 non-null float64\n",
      "smart_222_raw           81408 non-null float64\n",
      "smart_223_normalized    143898 non-null float64\n",
      "smart_223_raw           143898 non-null float64\n",
      "smart_224_normalized    81408 non-null float64\n",
      "smart_224_raw           81408 non-null float64\n",
      "smart_225_normalized    62490 non-null float64\n",
      "smart_225_raw           62490 non-null float64\n",
      "smart_226_normalized    81408 non-null float64\n",
      "smart_226_raw           81408 non-null float64\n",
      "smart_235_normalized    234 non-null float64\n",
      "smart_235_raw           234 non-null float64\n",
      "smart_240_normalized    6699773 non-null float64\n",
      "smart_240_raw           6699773 non-null float64\n",
      "smart_241_normalized    6611702 non-null float64\n",
      "smart_241_raw           6611702 non-null float64\n",
      "smart_242_normalized    6611468 non-null float64\n",
      "smart_242_raw           6611468 non-null float64\n",
      "smart_250_normalized    808 non-null float64\n",
      "smart_250_raw           808 non-null float64\n",
      "smart_251_normalized    808 non-null float64\n",
      "smart_251_raw           808 non-null float64\n",
      "smart_252_normalized    808 non-null float64\n",
      "smart_252_raw           808 non-null float64\n",
      "smart_254_normalized    7859 non-null float64\n",
      "smart_254_raw           7859 non-null float64\n",
      "smart_255_normalized    0 non-null float64\n",
      "smart_255_raw           0 non-null float64\n",
      "dtypes: float64(100), int64(2), object(3)\n",
      "memory usage: 7.1+ GB\n"
     ]
    }
   ],
   "source": [
    "# View information about the DataFrame\n",
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reviewing the concise summary of the DataFrame information, we should focus on the non-null and data type values for each feature, as well as the DataFrame memory usage. \n",
    "\n",
    "As we can see, the DataFrame is using over 7GB of memory. We must take into consideration any resource limitations in our environment and select only the most relevant features, as well as avoid features with a low count of non-null values in comparison to the over all observation, or record count of 8,989,492.\n",
    "\n",
    "Using this approach, we narrowed down our features of interest to 23: 1, 2, 3, 4, 5, 7, 9, 10, 12, 187, 188, 189, 190, 191, 192, 193, 194, 197, 198, 199, 240, 241, 242.\n",
    "\n",
    "However, this can still be considered a larger feature set in environments with resource limitations. If you fall in this category, then we would recommend narrowing this feature set down even more. To do this, a little online research is required to understand what the SMART stats represent and what others with IT Operations expertise suggest. \n",
    "\n",
    "The outcome of our research was to include the 4 observation descriptive features, the y variable (failure), and 15 SMART metrics. The 15 SMART metrics were determined by the following: \n",
    "\n",
    "First we included the [5 SMART metrics BackBlaze](https://www.backblaze.com/blog/hard-drive-smart-stats/) uses in their analysis: smart_5 (Reallocated Sector Count), smart_187 (Reported Uncorrected Errors), smart_188 (Command Timeout), smart_197 (Current Pending Sector Count), smart_198 (Offline Uncorrectable). \n",
    "\n",
    "After reviewing the [definitions](https://www.backblaze.com/blog-smart-stats-2014-8.html) of the remaining metrics the following were some basic metrics that made sense to check as well:\n",
    "smart_9 (Power On Hours), smart_193 (Load Cycle Count), smart_194 (Temperature Celsious), smart_241 (Total Logical Block Addressing Write), smart_242 (Total Logical Block Addressing Read). \n",
    "\n",
    "Initially we had thought to include the five new attributes recently added in 2018: smart_177 (Wear Range Delta), smart_179 (Used Reserve Block Count Total), smart_181 (Program Fail Count Total), smart_182 (Erase Fail Count), smart_235 (Good Block Count and System Free Block Count), however for this analysis the data is too sparse to aid in our perdictions, so we ultimately decided to leave them out for the time being.\n",
    "\n",
    "Finally we decided that including both the raw and normalized values for each SMART metric was redundant, so we chose to go with the 'raw', non-transformed values. If normalized is required later for our analysis, we can normalize it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8949492 entries, 0 to 100349\n",
      "Data columns (total 11 columns):\n",
      "date              8949492 non-null datetime64[ns]\n",
      "serial_number     8949492 non-null object\n",
      "model             8949492 non-null object\n",
      "capacity_bytes    8949492 non-null int64\n",
      "failure           8949492 non-null int64\n",
      "smart_5_raw       8949141 non-null float64\n",
      "smart_9_raw       8949141 non-null float64\n",
      "smart_193_raw     8881919 non-null float64\n",
      "smart_194_raw     8948907 non-null float64\n",
      "smart_197_raw     8948907 non-null float64\n",
      "smart_198_raw     8948907 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(6), int64(2), object(2)\n",
      "memory usage: 819.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# List of final features selected\n",
    "df_selected_features = ['date', 'serial_number', 'model','capacity_bytes',\n",
    "                        'failure', 'smart_5_raw', 'smart_9_raw',\n",
    "                        'smart_193_raw','smart_194_raw','smart_197_raw', \n",
    "                        'smart_198_raw'\n",
    "                        ]\n",
    "\n",
    "# 'smart_187_raw', 'smart_188_raw', 'smart_241_raw','smart_242_raw'\n",
    "\n",
    "# Remove all columns we no longer need for our analysis\n",
    "df = df[df_selected_features]\n",
    "\n",
    "# Check proper columns were removed\n",
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)\n",
    "Now that we have narrowed our dataset to just the relevant features that we feel are important for our analysis, it is time to start learning and understanding our dataset. During this step, we will note datapoints that need cleanses or corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8949492 entries, 0 to 100349\n",
      "Data columns (total 11 columns):\n",
      "date              8949492 non-null datetime64[ns]\n",
      "serial_number     8949492 non-null object\n",
      "model             8949492 non-null object\n",
      "capacity_bytes    8949492 non-null int64\n",
      "failure           8949492 non-null int64\n",
      "smart_5_raw       8949141 non-null float64\n",
      "smart_9_raw       8949141 non-null float64\n",
      "smart_193_raw     8881919 non-null float64\n",
      "smart_194_raw     8948907 non-null float64\n",
      "smart_197_raw     8948907 non-null float64\n",
      "smart_198_raw     8948907 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(6), int64(2), object(2)\n",
      "memory usage: 819.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column from object to date data type.\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Check data types properly converted\n",
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>model</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>failure</th>\n",
       "      <th>smart_5_raw</th>\n",
       "      <th>smart_9_raw</th>\n",
       "      <th>smart_193_raw</th>\n",
       "      <th>smart_194_raw</th>\n",
       "      <th>smart_197_raw</th>\n",
       "      <th>smart_198_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>Z305B2QN</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18766.0</td>\n",
       "      <td>34066.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>PL1331LAHG1S4H</td>\n",
       "      <td>HGST HMS5C4040ALE640</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8840.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>ZA16NQJR</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6725.0</td>\n",
       "      <td>3467.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>ZA18CEBT</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>ZA18CEBS</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3701.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   serial_number                 model  capacity_bytes  failure  \\\n",
       "0 2018-02-04        Z305B2QN           ST4000DM000   4000787030016        0   \n",
       "1 2018-02-04  PL1331LAHG1S4H  HGST HMS5C4040ALE640   4000787030016        0   \n",
       "2 2018-02-04        ZA16NQJR          ST8000NM0055   8001563222016        0   \n",
       "3 2018-02-04        ZA18CEBT          ST8000NM0055   8001563222016        0   \n",
       "4 2018-02-04        ZA18CEBS          ST8000NM0055   8001563222016        0   \n",
       "\n",
       "   smart_5_raw  smart_9_raw  smart_193_raw  smart_194_raw  smart_197_raw  \\\n",
       "0          0.0      18766.0        34066.0           22.0            0.0   \n",
       "1          0.0       8840.0           93.0           33.0            0.0   \n",
       "2          0.0       6725.0         3467.0           35.0            0.0   \n",
       "3          0.0       3702.0         2111.0           39.0            0.0   \n",
       "4          0.0       3701.0         1953.0           37.0            0.0   \n",
       "\n",
       "   smart_198_raw  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview our refined DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are (105004,) hard drives and (53,) different hard drive models.\n"
     ]
    }
   ],
   "source": [
    "# Get number of hard drives\n",
    "num_hhd = df['serial_number'].value_counts().shape\n",
    "num_hhd_models = df['model'].value_counts().shape\n",
    "\n",
    "print('There are {0} hard drives and {1} different hard drive models.'.format(num_hhd, num_hhd_models))\n",
    "\n",
    "# Replace Null Values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 336 hard drives that failed, failed dataframe shape (12836, 11)\n"
     ]
    }
   ],
   "source": [
    "# Get failed hard drives\n",
    "failed_hhd = df.loc[df.failure==1]['serial_number']\n",
    "\n",
    "# Create DataFrame of only failed hard drives.\n",
    "df_failed_hhd = df.loc[df[\"serial_number\"].isin(failed_hhd)]\n",
    "\n",
    "print('There were {0} hard drives that failed, failed dataframe shape {1}'.format(len(num_failed_hhd), df_failed_hhd.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-5b7620747fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcor_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         X = check_array(X, copy=self.copy, warn_on_dtype=True,\n\u001b[0;32m--> 334\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "y = df.failure\n",
    "x = df[['smart_5_raw', 'smart_9_raw',\n",
    "        'smart_193_raw','smart_194_raw','smart_197_raw', \n",
    "        'smart_198_raw']]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "cor_x = MinMaxScaler().fit_transform(x)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(cor_x, y, test_size=0.2)\n",
    "print (x_train.shape, y_train.shape)\n",
    "print (x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
